{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on PyOpenCL mainly.\n",
    "## See original notes by Derek Mendez here: \n",
    "http://prickly-pythons.github.io/python_code/pricklies_speedops.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl\n",
    "import numpy as np\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method # 1: pure numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a method that will \n",
    "# calculate I(q) where q is a vector \n",
    "# and I is a complex number:\n",
    "def method1(q_vecs, atom_vecs):\n",
    "    Nq = q_vecs.shape[0]\n",
    "    ampsR = np.zeros( Nq ) \n",
    "    ampsI = np.zeros( Nq )\n",
    "    for i_q, q in enumerate( q_vecs):\n",
    "        qx,qy,qz = q\n",
    "        for i_atom, atom in enumerate( atom_vecs):\n",
    "            ax,ay,az = atom\n",
    "            phase = qx*ax + qy*ay + qz*az\n",
    "            ampsR[i_q] += np.cos( -phase)\n",
    "            ampsI[i_q] += np.sin( -phase)\n",
    "    I = ampsR**2 + ampsI**2 \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up random set of q (qx,qy,qz) vectors and atom_vecs vectors\n",
    "q_vecs = np.random.random((10000, 3))\n",
    "# Pick a random set of ax,ay,az (100 atom vectors)\n",
    "atom_vecs = np.random.random((100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8712.12100683, 9619.37310958, 8437.28900954, 9284.73212745,\n",
       "       9046.97141614, 9559.18943437, 9876.47812006, 9052.87485658,\n",
       "       8254.13471571, 9499.61685364])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timing of this method:\n",
    "t1 = time.time()\n",
    "I = method1(q_vecs, atom_vecs)\n",
    "t2 = time.time()\n",
    "I[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1 took 4.56 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Method 1 took %.4s seconds' % (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "OBS: You can also do profiling of method1 by creating a separate file, see profiling_method1.py.\n",
    "I cloned and installed the profiler from:  https://github.com/rkern/line_profiler. Also, I changed the first line of kernprof.py to  !/Users/Karen/anaconda2/bin/python2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run profiling with:\n",
    "```\n",
    "kernprof -l profiling_method1.py\n",
    "py2 -m line_profiler profiling_method1.py.lprof\n",
    "```\n",
    "Which gives me:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 7.496 s\n",
    "File: profiling_method1.py\n",
    "Function: method1 at line 6\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     6                                           @profile  # this bit is important!\n",
    "     7                                           def method1(q_vecs, atom_vecs):\n",
    "     8         1            6      6.0      0.0      Nq = q_vecs.shape[0]\n",
    "     9         1           58     58.0      0.0      ampsR = np.zeros( Nq ) \n",
    "    10         1           31     31.0      0.0      ampsI = np.zeros( Nq )\n",
    "    11     10001         7554      0.8      0.1      for i_q, q in enumerate( q_vecs):\n",
    "    12     10000        14548      1.5      0.2          qx,qy,qz = q\n",
    "    13   1010000       673043      0.7      9.0          for i_atom, atom in enumerate( atom_vecs):\n",
    "    14   1000000      1449462      1.4     19.3              ax,ay,az = atom\n",
    "    15   1000000       929126      0.9     12.4              phase = qx*ax + qy*ay + qz*az\n",
    "    16   1000000      2241111      2.2     29.9              ampsR[i_q] += np.cos( -phase)\n",
    "    17   1000000      2180874      2.2     29.1              ampsI[i_q] += np.sin( -phase)\n",
    "    18         1          191    191.0      0.0      I = ampsR**2 + ampsI**2 \n",
    "    19         1            1      1.0      0.0      return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Method # 2: Embarrassingly parallel\n",
    "Using multiple processors to speed up method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def method2(q_vecs, atom_vecs, my_method, n_jobs=4,):\n",
    "    q_vecs_split = np.array_split(q_vecs, n_jobs)\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(my_method)(qs,atom_vecs) \n",
    "        for qs in q_vecs_split)\n",
    "    return np.concatenate(results,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing of this method:\n",
    "t1 = time.time()\n",
    "I = method2(q_vecs, atom_vecs, my_method=method1, n_jobs=4)\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 2 took 1.27 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Method 2 took %.4s seconds' % (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method # 3: pure numpy\n",
    "First, let's check configuration of numpy: I installed openblas, and re-installed numpy directly from github with a configuration to use OpenBlas, as described here: \n",
    "[https://dedupe.io/developers/library/en/latest/OSX-Install-Notes.html]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapack_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/opt/openblas/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "blas_opt_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/opt/openblas/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "openblas_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/opt/openblas/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "blis_info:\n",
      "  NOT AVAILABLE\n",
      "openblas_lapack_info:\n",
      "    libraries = ['openblas', 'openblas']\n",
      "    library_dirs = ['/usr/local/opt/openblas/lib']\n",
      "    define_macros = [('HAVE_CBLAS', None)]\n",
      "    language = c\n",
      "lapack_mkl_info:\n",
      "  NOT AVAILABLE\n",
      "blas_mkl_info:\n",
      "  NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just numpy is SUPER fast, but memory intensive because it stores the phase terms as opposed to computing them on the fly. Let's time it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 3 took 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "def method3(q_vecs, atom_vecs):\n",
    "    phases = np.dot( q_vecs, atom_vecs.T) \n",
    "    # T is the transpose, hence (Nq x 3) dotted with (3 x Natom)\n",
    "    # This results in an (Nq x Natom) array\n",
    "    \n",
    "    #In the end we want Nq amplitudes (both real and imaginary)\n",
    "    cosph = np.cos( -phases) \n",
    "    sinph = np.sin( -phases)\n",
    "    ampsR = np.sum( cosph, axis=1) # summing over the atoms axis... \n",
    "    ampsI = np.sum( sinph, axis=1)\n",
    "\n",
    "    # Take the mod-squared and return \n",
    "    I = ampsR**2 + ampsI**2 \n",
    "    return I\n",
    "# Timing this method:\n",
    "t1 = time.time()\n",
    "I = method3(q_vecs, atom_vecs)\n",
    "t2 = time.time()\n",
    "print('Method 3 took %.4s seconds' % (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method # 4: numexpr\n",
    "Introducing multi-threading to speed-up element-wise numpy operations!<br> \n",
    "Can somtimes make numpy run faster, but not really in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4 took 0.01 seconds\n"
     ]
    }
   ],
   "source": [
    "def method4(q_vecs, atom_vecs):\n",
    "    phases = np.dot( q_vecs, atom_vecs.T) # T is the transpose, hence (Nq x 3) dotted with (3 x Natom)\n",
    "    # This results in an (Nq x Natom) array\n",
    "    \n",
    "    # In the end we want Nq amplitudes (both real and imaginary)\n",
    "    cosph = ne.evaluate('cos( -phases)')\n",
    "    sinph = ne.evaluate('sin( -phases)')\n",
    "    ampsR = np.sum( cosph, axis=1) # summing over the atoms axis... \n",
    "    ampsI = np.sum( sinph, axis=1)\n",
    "\n",
    "    # Take the mod-squared and return \n",
    "    #I = ne.evaluate('ampsR**2 + ampsI**2')\n",
    "    I = ampsR**2 + ampsI**2 \n",
    "    return I\n",
    "# Timing this method:\n",
    "t1 = time.time()\n",
    "I = method4(q_vecs, atom_vecs)\n",
    "t2 = time.time()\n",
    "print('Method 4 took %.4s seconds' % (t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method # 5: OpenCL\n",
    "Let's start by looking up the platform and GPU(s) of this computer, using pyopencl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "def get_context_queue():\n",
    "#   list the platforms\n",
    "    platforms = cl.get_platforms()\n",
    "    print(\"Found platforms (will use first listed):\", platforms)\n",
    "#   select the gpu\n",
    "    my_gpu = platforms[0].get_devices(\n",
    "        device_type=cl.device_type.GPU)\n",
    "    assert( my_gpu)\n",
    "    print(\"Found GPU(s):\", my_gpu)\n",
    "#   create the context for the gpu, and the corresponding queue\n",
    "    context = cl.Context(devices=my_gpu)\n",
    "    queue = cl.CommandQueue(context)\n",
    "    return context, queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Found platforms (will use first listed):', [<pyopencl.Platform 'Apple' at 0x7fff0000>])\n",
      "('Found GPU(s):', [<pyopencl.Device 'Iris Pro' on 'Apple' at 0x1024500>])\n"
     ]
    }
   ],
   "source": [
    "context,queue = get_context_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyopencl.array as clarray\n",
    "def method5( q_vecs, atom_vecs, context, queue):\n",
    "    Nato = atom_vecs.shape[0]\n",
    "    Nq = q_vecs.shape[0]\n",
    "    # these are the output host buffers which will also be transferred to the device, updated on the device and then copied back to the host.\n",
    "    ampsR = np.ascontiguousarray(np.zeros( Nq, dtype=np.float32) )\n",
    "    ampsI = np.ascontiguousarray(np.zeros( Nq, dtype=np.float32) )\n",
    "    # OpenCL C source code , this is the instructions to the GPU workers\n",
    "    # note this code is essentially the inner-most loop of method 1, such that\n",
    "    # each worker is doing a single iteration of the outer-loop of method 1.\n",
    "    # this allows for insane speedups, without the need to use excess memory\n",
    "    # as in the numpy case (although GPUs have limited memory)\n",
    "    kernel = \"\"\" \n",
    "    __kernel void sim_amps(__global float* q_vecs,\n",
    "                            __global float* atom_vecs,\n",
    "                             __global float* ampsR,\n",
    "                             __global float* ampsI,\n",
    "                             int Nq, int Natoms){\n",
    "    //  this is the unique ID of each worker, and each worker will be loading a single q vec\n",
    "        int g_i = get_global_id(0);\n",
    "        float qx,qy,qz,ax,ay,az, cph, sph, phase;\n",
    "    //  we pass 1D arrays to openCL, in row-major order\n",
    "        qx = q_vecs[g_i*3];\n",
    "        qy = q_vecs[g_i*3+1];\n",
    "        qz = q_vecs[g_i*3+2];\n",
    "        for(int i =0; i < Natoms; i++){\n",
    "            ax = atom_vecs[i*3];\n",
    "            ay = atom_vecs[i*3+1];\n",
    "            az = atom_vecs[i*3+2];\n",
    "            phase = ax*qx + ay*qy + az*qz;\n",
    "            cph = native_cos(phase); // native openCL trig functions\n",
    "            sph = native_sin(phase);\n",
    "            ampsR[g_i] += cph;\n",
    "            ampsI[g_i] += sph;\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    #   setup opencl, compile bugs will show up here\n",
    "    program = cl.Program(context, kernel).build()\n",
    "\n",
    "#   move host arrays to GPU device, note forcing q_vecs and atom_vecs to be contiguous , ampsR and ampsI are already contiguous\n",
    "    qs_dev = clarray.to_device(queue, np.ascontiguousarray(q_vecs.astype(np.float32)))\n",
    "    atoms_dev = clarray.to_device(queue, np.ascontiguousarray(atom_vecs.astype(np.float32)))\n",
    "    ampsR_dev = clarray.to_device(queue, ampsR)\n",
    "    ampsI_dev = clarray.to_device(queue, ampsI)\n",
    "\n",
    "#   specify scalar args (just tell openCL which kernel args are scalar)\n",
    "    program.sim_amps.set_scalar_arg_dtypes(\n",
    "            [None, None, None,None,np.int32, np.int32])\n",
    "#   run the kernel\n",
    "#   note there are 3 pre-arguments to our kernel, these are the queue, \n",
    "#   the total number of workers, and the desired worker-group size. \n",
    "#   Leaving worker-group size as None lets openCL decide a value (I think)\n",
    "    program.sim_amps(queue, (Nq,), None, qs_dev.data, atoms_dev.data, \n",
    "        ampsR_dev.data, ampsI_dev.data, np.int32(Nq), np.int32(Nato))\n",
    "\n",
    "#   transfer data from device back to host\n",
    "#    you can try to optimize enqueue_copy by passing different flags \n",
    "    cl.enqueue_copy(queue, ampsR, ampsR_dev.data)\n",
    "    cl.enqueue_copy(queue, ampsI, ampsI_dev.data)\n",
    "    \n",
    "    I = ampsR**2 + ampsI**2\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of q and atom vectors,<br>\n",
    "we will se a big improvement in time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vecs = np.random.random((100000, 3))\n",
    "atom_vecs = np.random.random((1000, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 4 took 1.30 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([980281.77204445, 953003.89850894, 932079.88938346, 931743.56519526,\n",
       "       966050.92340825, 960212.25987076, 848684.89946519, 868769.74929962,\n",
       "       887698.05051446, 988611.67544165])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "I = method4(q_vecs, atom_vecs)\n",
    "t2 = time.time()\n",
    "print('Method 4 took %.4s seconds' % (t2-t1))\n",
    "I[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 5 took 0.03 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([980320.7 , 953040.9 , 932117.3 , 931782.4 , 966091.9 , 960250.1 ,\n",
       "       848720.5 , 868805.4 , 887733.75, 988650.5 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "I = method5(q_vecs, atom_vecs, context, queue)\n",
    "t2 = time.time()\n",
    "print('Method 5 took %.4s seconds' % (t2-t1))\n",
    "I[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
